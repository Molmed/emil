##' Batch design and test of classifiers
##'
##' @param type Same as for \code{\link{design}} but can take multiple types.
##' @param x Dataset, see \code{\link{design}}.
##' @param y Response vector. Can be either factor (for classification), numeric
##'   (for regression), \code{\link{Surv}} (for survival analysis) or any other
##'   class, as long as the algorithm specified in \code{type} can handle the
##'   type of data it is given.
##' @param param Additional parameters sent to the design function. If multiple
##'   classifier types are used it should be a list of lists named after the types.
##'   See \code{\link{design}} for more details.
##' @param ncv Number of crossvaldiation folds used for parameter estimation.
##' @param subset Subset of data to design on.
##' @param test.subset Logical or numerical matrix, list or vector that specifies
##'   which observations that are to be held out from design and instead be predicted
##'   by the classifier. Typically generated by \code{\link{crossval.groups}} or
##'   \code{\link{holdout.groups}}. If crossvalidation is used the results from each
##'   fold will be combined into a single object (unless \code{save.fits=TRUE}).
##' @param tune.surv When doing survival regression with a method that produce
##'   continuous predictions, e.g. risk scores, cutoffs for turning them into
##'   discrete groups that maximize survival difference can be automatically be
##'   serched for. However to avoid overfitting a fraction of the observations
##'   can be left out ... TODO!
##' @param assemble Whether to assemble results from each set of crossvalidation
##'   folds to a single object.
##' @param do.vimp Whether to calculate and return variable importance. Note
##'   that not all classifier types support this, e.g. kNN. Can be
##'   specified is several ways:
##'   \tabular{ll}{
##'     \code{TRUE} \tab Calculate for all types possible (default). Ignore
##'       unsupported types.\cr
##'     \code{FALSE} \tab Do not calculate for any type.\cr
##'     named logical vector \tab Typewise specification. The element names should
##'       correspond to the values in \code{type}. Unspecified types will not have
##'       variable importance calculated.\cr
##'     unnamed logical vector \tab Must have the same length as type.\cr
##'   }
##'   See \code{\link{vimp}} for more details.
##' @param do.roc Whether to calculate \code{\link{roc.measures}}.
##' @param pre.trans Transformation to be applied to the data before
##'   classification, see \code{\link{design}} for details.
##' @param permute.y Logical, whether the response should be permuted before
##'   testing. This serves as a sanity check to be compared with non-permuted
##'   results.
##' @param save.fits Logical, whether to save the fitted classifiers. Might be
##'   memory demanding depending on classifier type. If \code{TRUE} crossvalidation folds
##'   will not be combined since that would discard the fitted classifiers.
##' @param save.prefix Results will be saved in multiple files (to allow
##'   resuming and parallelization) named by this prefix. The prefix may include
##'   the path to a directory. To assemble the files after calculation is
##'   complete use \code{\link{batch.assemble}}.
##' @param create.dir Logical, whether the path included in \code{save.prefix}
##'   should be created if not existing. User will be prompted if unspecified
##' @param verbose Logical.
##' @param ... Sent to \code{\link{predict}}.
##' @return A list tree of fitted classifiers and/or test results, depending on
##'   \code{test.subset} and \code{save.fits}.
##' @examples
##' y <- factor(runif(100) < .3)
##' x <- matrix(rnorm(100*12), 100, 12) + .8*(y == "TRUE")
##' params <- list(rf=list(mtry=c(1,3,5)))
##' ho <- holdout.groups(y, 1/3, 3)
##' pred <- batch.design(c("qda", "rf"), x, y, params, test.subset=ho)
##' @seealso design, batch.assemble
##' @author Christofer \enc{B채cklin}{Backlin}
##' @export
batch.design <- function(type, x, y, param=NULL, ncv=10, subset=TRUE,
                         test.subset=FALSE, tune.surv=NULL, assemble, 
                         do.vimp=FALSE, do.roc=TRUE,
                         pre.trans = NULL, permute.y=FALSE,
                         save.fits=FALSE, save.prefix=NULL, create.dir,
                         verbose = interactive(), ...){
    if(!verbose) cat <- function(...) invisible()

    if(!is.blank(save.prefix)) save.test(save.prefix, create.dir)
    if(is.Surv(y)) y <- as.outcome(y)
    n <- length(y)

    # Prepare parameters
    if(length(type) == 1 && !type %in% names(param)){
        param <- list(param)
        names(param) <- type
    }

    # Make sure test.subset is a list of logicals
    ts <- test.subset
    if(is.vector(ts)) ts <- list(ts)
    if(is.matrix(ts)) ts <- as.data.frame(ts)
    ts <- lapply(ts, function(my.ts){
        if(!is.logical(my.ts)){
            if(all(c(-1, 1) %in% sign(my.ts))) stop("ts contains mixed positive and negative values.")
            my.ts <- xor(1:n %in% abs(my.ts), my.ts[1] < 0) # xor takes care of negative numeric indexing
        }
        my.ts[-(1:n)[subset]] <- NA
        #my.ts[is.na(y)] <- NA
        return(my.ts)
    })
    if(missing(assemble)) assemble <- inherits(test.subset, "crossval") &&
                                      !is.na(attr(test.subset, "nfold")) &&
                                      !is.na(attr(test.subset, "nrep"))

    # Print work summary
    if(length(ts) > 1){
        cat("Starting design process.\nIn total the following number of classifiers will be fitted:\n")
        for(my.type in type){
            i <- if(is.null(param[[my.type]])) 1 else prod(sapply(param[[my.type]], length))
            if(i > 1) i <- ncv
            cat(sprintf("%8i %s\n", i*length(ts), my.type))
        }
    }
    if(!is.blank(save.prefix)){
        cat(sprintf("%i files will be generated.\n", length(ts)))
        if("crossval" %in% class(test.subset))
            cat("Results are saved to disk so predictions from matching crossvalidation folds will NOT be assembled. Run assemble.cv afterwards.\n")
    }

    # Variable importance
    if(is.factor(y)){
        if(length(levels(y)) > 2){
            if(any(do.vimp)) cat("Variable importance is only implemented for binary classification problems.\n")
            do.vimp <- sapply(type, function(my.type) FALSE)
        } else {
            alert.missing <- !missing(do.vimp)
            has.vimp <- sapply(type, function(x) exists(sprintf("vimp.%s", x)))
            if(is.null(names(do.vimp))){
                if(!length(do.vimp) %in% c(1, length(type))){
                    cat("NOTE: Length of `do.vimp` does not match length of `type`.\n")
                }
                do.vimp <- rep(do.vimp, ceiling(length(type)/length(do.vimp)))[1:length(type)]
                names(do.vimp) <- type
            } else {
                missing.vimp <- type[!type %in% names(do.vimp)]
                do.vimp[missing.vimp] <- has.vimp[missing.vimp]
                if(any(!names(do.vimp) %in% type)){
                    cat(sprintf("NOTE: Types %s in `do.vimp` are not in `type` and will be ignored.\n",
                        paste("`", names(do.vimp)[!names(do.vimp) %in% type], "`", sep="", collapse=", ")))
                }
                do.vimp <- do.vimp[type]
            }
            if(alert.missing && any(do.vimp & !has.vimp)){
                cat(sprintf("NOTE: Variable importance will NOT be calculated for %s, no method found.\n",
                            paste(sprintf("`%s`", type[do.vimp & !has.vimp]), collapse=", ")))
            }
            do.vimp <- do.vimp & has.vimp
        }
        if(any(do.vimp)){
            cat(sprintf("Variable importance will be calculated for %s.\n",
                paste(sprintf("`%s`", type[!is.na(do.vimp) & do.vimp]), collapse=", ")))
        } else {
            cat("Variable importance will not be calculated.\n")
        }
    } else {
        do.vimp <- rep(FALSE, length(type))
        names(do.vimp) <- type
    }

    # ROC-measures
    if(do.roc && (!is.factor(y) || length(levels(y)) != 2)){
        if(!missing(do.roc))
            cat(sprintf("ROC-measures are only implemented for binary classification problems and will therefore not be calculated.\n"))
        do.roc <- FALSE
    }

    # Design
    res <- foreach(my.ts = ts, ts.i=1:length(ts)) %dopar% {
        if(!is.blank(save.prefix)){
            my.file <- sprintf(sprintf("%%s_%%0%ii.Rdata", nchar(length(ts))), save.prefix, ts.i)
            if(file.exists(my.file)){
                cat(sprintf("%s already calculated.\n", my.file))
                return(NULL)
            }
        }
        if(permute.y) y <- sample(y)
        res.type <- foreach(my.type = type) %do% {
            tryCatch({
                # Fit classifier
                design.idx <- na.fill(!my.ts, FALSE)
                if(!is.blank(tune.surv)){
                    if(tune.surv < 1){
                        tune.idx <- na.fill(holdout.groups(y, frac=tune.surv, subset=design.idx), FALSE)
                        design.idx <- design.idx != tune.idx
                    } else {
                        tune.idx <- design.idx
                    }
                }
                fit <- design(my.type, x, y, param[[my.type]], ncv, design.idx, pre.trans=pre.trans)

                # Test fit and calculate AUC and ROC confusion table if possible
                if(!identical(my.ts, FALSE)){
                    pred <- predict(fit, fit$pre.trans(x[na.fill(my.ts, FALSE),, drop=FALSE]), ...)
                    if(do.roc && !assemble)
                        pred <- roc.measures(y[!is.na(my.ts) & my.ts], pred)
                    if(is.outcome(y) && !is.blank(tune.surv)){
                        tune.pred <- predict(fit, x[tune.idx,])
                        thres <- tune.survival(tune.pred$risk, y[tune.idx])
                        pred$pred <- factor(sapply(pred$risk, function(p) sum(p > thres)),
                                            levels=0:1, labels=c("low", "high"))
                    }
                } else {
                    pred <- NULL
                }

                # Calculate variable importance
                if(do.vimp[my.type]){
                    my.vimp <- if(do.vimp[my.type]) classify::vimp(fit) else rep(NA, ncol(x))
                    # The classify::vimp is to not use other packages' vimp functions
                    # if they exists, e.g. in randomSurvivalForest
                } else {
                    my.vimp <- NULL
                }

                return(c(if(save.fits) list(fit=fit) else NULL,
                         pred,
                         if(do.vimp[my.type]) list(vimp=my.vimp) else NULL))
            }, error = function(e){
                return(list(error=e))
            })
        }
        names(res.type) <- type

        # Return
        if(is.blank(save.prefix)){
            cat(".")
            return(res.type)
        } else {
            save(ts.i, res.type, file=my.file)
            cat(sprintf("%s completed.\n", my.file))
            return(NULL)
        }
    }
    if(!is.blank(save.prefix)) return(invisible())
    cat("\n")
    if(assemble){
        try(res <- assemble.cv(res, y, subset=subset, test.subset=test.subset))
        if(do.roc){
            cat("Calculating ROC-measures.\n")
            res <- roc.measures(y, res)
        }
    }
    cat("\n")
    return(res)
}


##' Assemble results from a clasifier batch saved on disc
##' 
##' @param save.prefix Path and prefix to result files. 
##' @param func Optional, function to be applied to each loaded file. Useful
##'   when there are many files and only parts of the results are needed.
##'   Fitted classifiers can be large and can be removed by setting \code{func}
##'   to \code{\link{remove.fits}}.
##' @param ... Sent to \code{\link{foreach}}.
##' @param verbose Logical.
##' @return Results on the same form as \code{\link{batch.design}}.
##' @examples
##' \dontrun{batch.design("qda", x, y, test.subset=holdout.groups(y, 1/3, 10),
##'              save.prefix="result/test")
##' pred <- batch.assemble("results/test")}
##' @seealso batch.design
##' @author Christofer \enc{B채cklin}{Backlin}
##' @export
batch.assemble <- function(save.prefix, func=identity, ..., verbose=interactive()){
    # Check filenames
    if(!grepl("/", save.prefix)) save.prefix <- sprintf("./%s", save.prefix)
    files <- dir(path    = sub("/[^/]*$", "", save.prefix),
                 pattern = sprintf("^%s", sub(".*/", "", save.prefix)),
                 full.names = TRUE)
    if(is.blank(files))
        stop("No batch found.")
    prefix <- sub("_\\d+\\.Rdata", "", files)
    if(length(unique(prefix)) != 1)
        stop("Multiple runs match save.prefix.")
    rep.no <- as.integer(sub(paste("^", prefix[1], "_", sep=""), "", sub("\\.Rdata$", "", files)))
    if(any(!1:max(rep.no) %in% rep.no))
        warning("Batch seems to be incomplete.")

    cat(sprintf("Assembling %i files\n", length(files)))
    if(verbose) pb <- txtProgressBar(max=length(files), style=3)
    file.order <- order(rep.no)
    res <- lapply(1:length(files), function(i){
        load(files[file.order[i]])
        if(verbose) setTxtProgressBar(pb, i)
        return(func(res.type))
    })
    if(verbose) close(pb)
    return(res)
}

##' Plugin function to batch assemble
##' 
##' @param x Prediction object.
##' @return Same object but without any fitted classifiers.
##' @seealso batch.assemble
##' @author Christofer \enc{B채cklin}{Backlin}
##' @export
remove.fits <- function(x){
    lapply(x, function(y) y[!grepl("fit", names(y))])
}


##' Variable importance for a batch of trained classifiers.
##' 
##' @param batch Trained classifiers as returned by \code{\link{batch.design}}.
##' @param param List of arguments passed to the class methods.
##' @return A list of variable importance matrices.
##' @examples
##' \dontrun{batch <- batch.design(c("nsc", "rf"), my.data, my.class.labels)
##' batch.vimp(batch, list(rf=list(type=2)))}
##' @seealso vimp
##' @author Christofer \enc{B채cklin}{Backlin}
##' @export
batch.vimp <- function(batch, param=NULL){
    method.exists <- sapply(sprintf("vimp.%s", names(batch[[1]])), exists)
    if(all(!method.exists))
        stop("No appropriate methods found.")
    if(any(!method.exists))
        warning(sprintf("No appropriate method found for classifier(s) %s.",
                paste(sprintf("`%s`", names(batch[[1]])[!method.exists]), collapse=", ")))

    # Calculate
    return(lapply(batch, function(pred){
        sapply(names(pred), function(type){
            if(method.exists[sprintf("vimp.%s", type)]){
                do.call("vimp", c(list(pred[[type]]$fit), param[[type]]))
            } else {
                rep(NA, length(pred[[type]]$fit$descriptors))
            }
        })
    }))
}

